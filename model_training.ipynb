{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Load tabular data\n",
    "train = pd.read_excel(\"data/train.xlsx\")\n",
    "test  = pd.read_excel(\"data/test.xlsx\")\n",
    "\n",
    "# Make sure id exists\n",
    "if \"id\" not in train.columns:\n",
    "    train[\"id\"] = train.index.astype(str)\n",
    "if \"id\" not in test.columns:\n",
    "    test[\"id\"] = test.index.astype(str)\n",
    "\n",
    "# Image folders\n",
    "train_img_dir = \"images/train\"\n",
    "test_img_dir  = \"images/test\"\n",
    "\n",
    "# Image transforms (match ResNet expectations)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load pretrained ResNet18 and remove last classification layer\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "resnet.fc = nn.Identity()   # output becomes 512-d embedding\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_embedding(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(device)  # (1,3,224,224)\n",
    "    emb = resnet(x).squeeze(0).cpu().numpy()    # (512,)\n",
    "    return emb\n",
    "\n",
    "def build_embeddings(df, img_dir):\n",
    "    embs = []\n",
    "    kept_ids = []\n",
    "    for _id in tqdm(df[\"id\"].astype(str).tolist()):\n",
    "        path = os.path.join(img_dir, f\"{_id}.png\")\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        embs.append(get_embedding(path))\n",
    "        kept_ids.append(_id)\n",
    "    return np.vstack(embs), kept_ids\n",
    "\n",
    "# Build embeddings\n",
    "train_emb, train_ids = build_embeddings(train, train_img_dir)\n",
    "test_emb,  test_ids  = build_embeddings(test,  test_img_dir)\n",
    "\n",
    "print(\"Train embeddings:\", train_emb.shape)\n",
    "print(\"Test embeddings:\", test_emb.shape)\n",
    "\n",
    "# Save for reuse\n",
    "np.save(\"train_img_emb.npy\", train_emb)\n",
    "np.save(\"test_img_emb.npy\", test_emb)\n",
    "pd.Series(train_ids).to_csv(\"train_ids_used.csv\", index=False)\n",
    "pd.Series(test_ids).to_csv(\"test_ids_used.csv\", index=False)\n",
    "\n",
    "print(\"Saved embeddings âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70005fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel alive\n"
     ]
    }
   ],
   "source": [
    "print(\"kernel alive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e737e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\asus/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:13<00:00, 3.36MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16209/16209 [02:47<00:00, 96.89it/s]  \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5404/5404 [00:54<00:00, 99.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape: (3040, 512)\n",
      "Test embeddings shape: (1001, 512)\n",
      "Saved embeddings âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===================== IMPORTS =====================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# ===================== DEVICE =====================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ===================== LOAD DATA =====================\n",
    "train = pd.read_excel(\"data/train.xlsx\")\n",
    "test  = pd.read_excel(\"data/test.xlsx\")\n",
    "\n",
    "if \"id\" not in train.columns:\n",
    "    train[\"id\"] = train.index.astype(str)\n",
    "if \"id\" not in test.columns:\n",
    "    test[\"id\"] = test.index.astype(str)\n",
    "\n",
    "train_img_dir = \"images/train\"\n",
    "test_img_dir  = \"images/test\"\n",
    "\n",
    "# ===================== TRANSFORMS =====================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std =[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# ===================== MODEL =====================\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "resnet.fc = nn.Identity()   # remove classifier â†’ embeddings\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "# ===================== EMBEDDING FUNCTIONS =====================\n",
    "@torch.no_grad()\n",
    "def get_embedding(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    emb = resnet(x).squeeze(0).cpu().numpy()\n",
    "    return emb\n",
    "\n",
    "def build_embeddings(df, img_dir):\n",
    "    embs = []\n",
    "    ids  = []\n",
    "    for _id in tqdm(df[\"id\"].astype(str)):\n",
    "        path = os.path.join(img_dir, f\"{_id}.png\")\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        embs.append(get_embedding(path))\n",
    "        ids.append(_id)\n",
    "    return np.vstack(embs), ids\n",
    "\n",
    "# ===================== RUN =====================\n",
    "train_emb, train_ids = build_embeddings(train, train_img_dir)\n",
    "test_emb,  test_ids  = build_embeddings(test,  test_img_dir)\n",
    "\n",
    "print(\"Train embeddings shape:\", train_emb.shape)\n",
    "print(\"Test embeddings shape:\", test_emb.shape)\n",
    "\n",
    "# ===================== SAVE =====================\n",
    "np.save(\"train_img_emb.npy\", train_emb)\n",
    "np.save(\"test_img_emb.npy\", test_emb)\n",
    "\n",
    "pd.Series(train_ids).to_csv(\"train_ids_used.csv\", index=False)\n",
    "pd.Series(test_ids).to_csv(\"test_ids_used.csv\", index=False)\n",
    "\n",
    "print(\"Saved embeddings âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0564b76",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['9117000170', '6700390210', '7212660540', '8562780200', '7760400350',\\n       '464001025', '3432500486', '1126059095', '3876500290', '1865400075',\\n       ...\\n       '9407110710', '3523069060', '1788800630', '526059224', '2023049218',\\n       '4302201085', '3293700496', '6623400187', '5132000140', '1954420170'],\\n      dtype='object', name='id', length=3040)] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     30\u001b[39m test_small  = test_df[test_df[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).isin(test_ids)].copy()\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Sort to match embedding order\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m train_small = \u001b[43mtrain_small\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_ids\u001b[49m\u001b[43m]\u001b[49m.reset_index()\n\u001b[32m     34\u001b[39m test_small  = test_small.set_index(\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m).loc[test_ids].reset_index()\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTabular train rows:\u001b[39m\u001b[33m\"\u001b[39m, train_small.shape, \u001b[33m\"\u001b[39m\u001b[33mEmbeddings:\u001b[39m\u001b[33m\"\u001b[39m, train_emb.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1192\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1190\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1191\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1421\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1418\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m   1419\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index with multidimensional key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1361\u001b[39m, in \u001b[36m_LocIndexer._getitem_iterable\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1358\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m   1360\u001b[39m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m keyarr, indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._reindex_with_indexers(\n\u001b[32m   1363\u001b[39m     {axis: [keyarr, indexer]}, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1364\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1559\u001b[39m, in \u001b[36m_LocIndexer._get_listlike_indexer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1556\u001b[39m ax = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m   1557\u001b[39m axis_name = \u001b[38;5;28mself\u001b[39m.obj._get_axis_name(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1559\u001b[39m keyarr, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['9117000170', '6700390210', '7212660540', '8562780200', '7760400350',\\n       '464001025', '3432500486', '1126059095', '3876500290', '1865400075',\\n       ...\\n       '9407110710', '3523069060', '1788800630', '526059224', '2023049218',\\n       '4302201085', '3293700496', '6623400187', '5132000140', '1954420170'],\\n      dtype='object', name='id', length=3040)] are in the [index]\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load original data\n",
    "train_df = pd.read_excel(\"data/train.xlsx\")\n",
    "test_df  = pd.read_excel(\"data/test.xlsx\")\n",
    "\n",
    "if \"id\" not in train_df.columns:\n",
    "    train_df[\"id\"] = train_df.index.astype(str)\n",
    "if \"id\" not in test_df.columns:\n",
    "    test_df[\"id\"] = test_df.index.astype(str)\n",
    "\n",
    "# Load embeddings\n",
    "train_emb = np.load(\"train_img_emb.npy\")\n",
    "test_emb  = np.load(\"test_img_emb.npy\")\n",
    "\n",
    "train_ids = pd.read_csv(\"train_ids_used.csv\").iloc[:,0].astype(str).tolist()\n",
    "test_ids  = pd.read_csv(\"test_ids_used.csv\").iloc[:,0].astype(str).tolist()\n",
    "\n",
    "# Keep only rows that have embeddings\n",
    "train_small = train_df[train_df[\"id\"].astype(str).isin(train_ids)].copy()\n",
    "test_small  = test_df[test_df[\"id\"].astype(str).isin(test_ids)].copy()\n",
    "\n",
    "# Sort to match embedding order\n",
    "train_small = train_small.set_index(\"id\").loc[train_ids].reset_index()\n",
    "test_small  = test_small.set_index(\"id\").loc[test_ids].reset_index()\n",
    "\n",
    "print(\"Tabular train rows:\", train_small.shape, \"Embeddings:\", train_emb.shape)\n",
    "print(\"Tabular test rows :\", test_small.shape,  \"Embeddings:\", test_emb.shape)\n",
    "\n",
    "# Target\n",
    "y = train_small[\"price\"]\n",
    "X_tab = train_small.drop(columns=[\"price\"])\n",
    "\n",
    "# We'll add embeddings later after preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02f648f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train columns: ['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
      "train id dtype: int64\n",
      "sample train_ids_used: ['9117000170', '6700390210', '7212660540', '8562780200', '7760400350']\n",
      "sample train_df id: ['9117000170', '6700390210', '7212660540', '8562780200', '7760400350']\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_excel(\"data/train.xlsx\")\n",
    "print(\"train columns:\", train_df.columns.tolist())\n",
    "print(\"train id dtype:\", train_df[\"id\"].dtype if \"id\" in train_df.columns else \"NO id column\")\n",
    "\n",
    "train_ids = pd.read_csv(\"train_ids_used.csv\").iloc[:,0].astype(str)\n",
    "print(\"sample train_ids_used:\", train_ids.head().tolist())\n",
    "\n",
    "if \"id\" in train_df.columns:\n",
    "    print(\"sample train_df id:\", train_df[\"id\"].head().astype(str).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "757e2400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate train ids: 99\n",
      "Duplicate test ids : 8\n",
      "ids with embeddings: 3040 1001\n",
      "ids found in excel : 3040 1001\n",
      "Final aligned shapes:\n",
      "train_small: (3040, 21) train_emb_ok: (3040, 512)\n",
      "test_small : (1001, 20) test_emb_ok : (1001, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_excel(\"data/train.xlsx\")\n",
    "test_df  = pd.read_excel(\"data/test.xlsx\")\n",
    "\n",
    "# Make ids string everywhere\n",
    "train_df[\"id\"] = train_df[\"id\"].astype(str)\n",
    "test_df[\"id\"]  = test_df[\"id\"].astype(str)\n",
    "\n",
    "train_emb = np.load(\"train_img_emb.npy\")\n",
    "test_emb  = np.load(\"test_img_emb.npy\")\n",
    "\n",
    "train_ids = pd.read_csv(\"train_ids_used.csv\").iloc[:,0].astype(str)\n",
    "test_ids  = pd.read_csv(\"test_ids_used.csv\").iloc[:,0].astype(str)\n",
    "\n",
    "# Check duplicates\n",
    "print(\"Duplicate train ids:\", train_df[\"id\"].duplicated().sum())\n",
    "print(\"Duplicate test ids :\", test_df[\"id\"].duplicated().sum())\n",
    "\n",
    "# âœ… Build mapping id -> row index (first occurrence)\n",
    "train_map = train_df.drop_duplicates(\"id\").set_index(\"id\")\n",
    "test_map  = test_df.drop_duplicates(\"id\").set_index(\"id\")\n",
    "\n",
    "# âœ… Keep only ids that exist in tabular\n",
    "train_ids_ok = [i for i in train_ids if i in train_map.index]\n",
    "test_ids_ok  = [i for i in test_ids if i in test_map.index]\n",
    "\n",
    "print(\"ids with embeddings:\", len(train_ids), len(test_ids))\n",
    "print(\"ids found in excel :\", len(train_ids_ok), len(test_ids_ok))\n",
    "\n",
    "# âœ… Align in same order as embeddings (but only ids that exist)\n",
    "train_small = train_map.loc[train_ids_ok].reset_index()\n",
    "test_small  = test_map.loc[test_ids_ok].reset_index()\n",
    "\n",
    "# âœ… Trim embeddings to same length/order\n",
    "# We must trim embeddings using the same mask\n",
    "train_mask = [i in set(train_ids_ok) for i in train_ids]\n",
    "test_mask  = [i in set(test_ids_ok) for i in test_ids]\n",
    "\n",
    "train_emb_ok = train_emb[train_mask]\n",
    "test_emb_ok  = test_emb[test_mask]\n",
    "\n",
    "print(\"Final aligned shapes:\")\n",
    "print(\"train_small:\", train_small.shape, \"train_emb_ok:\", train_emb_ok.shape)\n",
    "print(\"test_small :\", test_small.shape,  \"test_emb_ok :\", test_emb_ok.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf87645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate train ids: 99\n",
      "Duplicate test ids : 8\n",
      "ids with embeddings: 3040 1001\n",
      "ids found in excel : 3040 1001\n",
      "Final aligned shapes:\n",
      "train_small: (3040, 21) train_emb_ok: (3040, 512)\n",
      "test_small : (1001, 20) test_emb_ok : (1001, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_excel(\"data/train.xlsx\")\n",
    "test_df  = pd.read_excel(\"data/test.xlsx\")\n",
    "\n",
    "# Make ids string everywhere\n",
    "train_df[\"id\"] = train_df[\"id\"].astype(str)\n",
    "test_df[\"id\"]  = test_df[\"id\"].astype(str)\n",
    "\n",
    "train_emb = np.load(\"train_img_emb.npy\")\n",
    "test_emb  = np.load(\"test_img_emb.npy\")\n",
    "\n",
    "train_ids = pd.read_csv(\"train_ids_used.csv\").iloc[:,0].astype(str)\n",
    "test_ids  = pd.read_csv(\"test_ids_used.csv\").iloc[:,0].astype(str)\n",
    "\n",
    "# Check duplicates\n",
    "print(\"Duplicate train ids:\", train_df[\"id\"].duplicated().sum())\n",
    "print(\"Duplicate test ids :\", test_df[\"id\"].duplicated().sum())\n",
    "\n",
    "# âœ… Build mapping id -> row index (first occurrence)\n",
    "train_map = train_df.drop_duplicates(\"id\").set_index(\"id\")\n",
    "test_map  = test_df.drop_duplicates(\"id\").set_index(\"id\")\n",
    "\n",
    "# âœ… Keep only ids that exist in tabular\n",
    "train_ids_ok = [i for i in train_ids if i in train_map.index]\n",
    "test_ids_ok  = [i for i in test_ids if i in test_map.index]\n",
    "\n",
    "print(\"ids with embeddings:\", len(train_ids), len(test_ids))\n",
    "print(\"ids found in excel :\", len(train_ids_ok), len(test_ids_ok))\n",
    "\n",
    "# âœ… Align in same order as embeddings (but only ids that exist)\n",
    "train_small = train_map.loc[train_ids_ok].reset_index()\n",
    "test_small  = test_map.loc[test_ids_ok].reset_index()\n",
    "\n",
    "# âœ… Trim embeddings to same length/order\n",
    "# We must trim embeddings using the same mask\n",
    "train_mask = [i in set(train_ids_ok) for i in train_ids]\n",
    "test_mask  = [i in set(test_ids_ok) for i in test_ids]\n",
    "\n",
    "train_emb_ok = train_emb[train_mask]\n",
    "test_emb_ok  = test_emb[test_mask]\n",
    "\n",
    "print(\"Final aligned shapes:\")\n",
    "print(\"train_small:\", train_small.shape, \"train_emb_ok:\", train_emb_ok.shape)\n",
    "print(\"test_small :\", test_small.shape,  \"test_emb_ok :\", test_emb_ok.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d353c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal X shape: (3040, 3839)\n",
      "Multimodal RMSE: 232377.74057089243\n",
      "Multimodal R2: 0.682903635612464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "y = train_small[\"price\"]\n",
    "X_tab = train_small.drop(columns=[\"price\"])\n",
    "\n",
    "cat_cols = X_tab.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = [c for c in X_tab.columns if c not in cat_cols]\n",
    "\n",
    "numeric_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_tf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_tf, num_cols),\n",
    "    (\"cat\", categorical_tf, cat_cols)\n",
    "])\n",
    "\n",
    "X_tab_processed = preprocess.fit_transform(X_tab)\n",
    "X_tab_dense = X_tab_processed.toarray() if hasattr(X_tab_processed, \"toarray\") else X_tab_processed\n",
    "\n",
    "X = np.hstack([X_tab_dense, train_emb_ok])\n",
    "print(\"Multimodal X shape:\", X.shape)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, pred) ** 0.5\n",
    "r2 = r2_score(y_val, pred)\n",
    "\n",
    "print(\"Multimodal RMSE:\", rmse)\n",
    "print(\"Multimodal R2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adbff195",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMultimodal RandomForest RMSE:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mrf_rmse\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMultimodal RandomForest R2:\u001b[39m\u001b[33m\"\u001b[39m, rf_r2)\n",
      "\u001b[31mNameError\u001b[39m: name 'rf_rmse' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Multimodal RandomForest RMSE:\", rf_rmse)\n",
    "print(\"Multimodal RandomForest R2:\", rf_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ace1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal RMSE: 232377.74057089243\n",
      "Multimodal R2: 0.682903635612464\n"
     ]
    }
   ],
   "source": [
    "print(\"Multimodal RMSE:\", rmse)\n",
    "print(\"Multimodal R2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aead55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ XGBoost Multimodal RMSE: 237397.52504185884\n",
      "ðŸ”¥ XGBoost Multimodal R2: 0.6690559387207031\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "xgb_pred = xgb_model.predict(X_val)\n",
    "\n",
    "xgb_rmse = mean_squared_error(y_val, xgb_pred) ** 0.5\n",
    "xgb_r2 = r2_score(y_val, xgb_pred)\n",
    "\n",
    "print(\"ðŸ”¥ XGBoost Multimodal RMSE:\", xgb_rmse)\n",
    "print(\"ðŸ”¥ XGBoost Multimodal R2:\", xgb_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f79afd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š MODEL COMPARISON\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rf_rmse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸ“Š MODEL COMPARISON\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRandomForest RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mrf_rmse\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRandomForest R2  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrf_r2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'rf_rmse' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“Š MODEL COMPARISON\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"RandomForest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"RandomForest R2  : {rf_r2:.4f}\")\n",
    "print()\n",
    "print(f\"XGBoost RMSE     : {xgb_rmse:.2f}\")\n",
    "print(f\"XGBoost R2       : {xgb_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd199865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multimodal RMSE: 232377.74057089243\n",
      "Multimodal R2: 0.682903635612464\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_val, pred) ** 0.5\n",
    "r2 = r2_score(y_val, pred)\n",
    "\n",
    "print(\"Multimodal RMSE:\", rmse)\n",
    "print(\"Multimodal R2:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94973ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save RF metrics with proper names\n",
    "rf_rmse = rmse\n",
    "rf_r2 = r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa87582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š MODEL COMPARISON\n",
      "----------------------------------------\n",
      "RandomForest RMSE: 232377.74\n",
      "RandomForest R2  : 0.6829\n",
      "\n",
      "XGBoost RMSE     : 237397.53\n",
      "XGBoost R2       : 0.6691\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“Š MODEL COMPARISON\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"RandomForest RMSE: {rf_rmse:.2f}\")\n",
    "print(f\"RandomForest R2  : {rf_r2:.4f}\")\n",
    "print()\n",
    "\n",
    "print(f\"XGBoost RMSE     : {xgb_rmse:.2f}\")\n",
    "print(f\"XGBoost R2       : {xgb_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "986f2e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA on Image Embeddings (Dimensionality Reduction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf314ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA explained variance: 0.75626576\n",
      "Train PCA shape: (3040, 64)\n",
      "Test PCA shape : (1001, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce CNN embeddings from 512 â†’ 64\n",
    "pca = PCA(n_components=64, random_state=42)\n",
    "\n",
    "train_img_pca = pca.fit_transform(train_emb_ok)\n",
    "test_img_pca  = pca.transform(test_emb_ok)\n",
    "\n",
    "print(\"PCA explained variance:\", pca.explained_variance_ratio_.sum())\n",
    "print(\"Train PCA shape:\", train_img_pca.shape)\n",
    "print(\"Test PCA shape :\", test_img_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea240202",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_tab_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Combine tabular + PCA image features\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train_mm_pca = np.hstack([\u001b[43mX_tab_train\u001b[49m.values, train_img_pca])\n\u001b[32m      5\u001b[39m X_test_mm_pca  = np.hstack([X_tab_test.values, test_img_pca])\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFinal multimodal train shape:\u001b[39m\u001b[33m\"\u001b[39m, X_train_mm_pca.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_tab_train' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Combine tabular + PCA image features\n",
    "X_train_mm_pca = np.hstack([X_tab_train.values, train_img_pca])\n",
    "X_test_mm_pca  = np.hstack([X_tab_test.values, test_img_pca])\n",
    "\n",
    "print(\"Final multimodal train shape:\", X_train_mm_pca.shape)\n",
    "print(\"Final multimodal test shape :\", X_test_mm_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf6071e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['price'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Tabular features (drop target)\u001b[39;00m\n\u001b[32m      2\u001b[39m X_tab_train = train_small.drop(\u001b[33m\"\u001b[39m\u001b[33mprice\u001b[39m\u001b[33m\"\u001b[39m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X_tab_test  = \u001b[43mtest_small\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTabular train shape:\u001b[39m\u001b[33m\"\u001b[39m, X_tab_train.shape)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTabular test shape :\u001b[39m\u001b[33m\"\u001b[39m, X_tab_test.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5603\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5455\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5456\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5457\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5464\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5465\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5467\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5468\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5601\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5602\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5603\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5606\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5607\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5609\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5610\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4810\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4810\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4813\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4852\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4850\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4851\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4852\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4853\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4855\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4856\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['price'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Tabular features (drop target)\n",
    "X_tab_train = train_small.drop(\"price\", axis=1)\n",
    "X_tab_test  = test_small.drop(\"price\", axis=1)\n",
    "\n",
    "print(\"Tabular train shape:\", X_tab_train.shape)\n",
    "print(\"Tabular test shape :\", X_tab_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28a751ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular train shape: (3040, 20)\n",
      "Tabular test shape : (1001, 20)\n"
     ]
    }
   ],
   "source": [
    "# Train tabular features + target\n",
    "X_tab_train = train_small.drop(\"price\", axis=1)\n",
    "y_train_tab = train_small[\"price\"]\n",
    "\n",
    "# Test tabular features (NO price column)\n",
    "X_tab_test = test_small.copy()\n",
    "\n",
    "print(\"Tabular train shape:\", X_tab_train.shape)\n",
    "print(\"Tabular test shape :\", X_tab_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "139fab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final multimodal train shape: (3040, 84)\n",
      "Final multimodal test shape : (1001, 84)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_mm_pca = np.hstack([X_tab_train.values, train_img_pca])\n",
    "X_test_mm_pca  = np.hstack([X_tab_test.values, test_img_pca])\n",
    "\n",
    "print(\"Final multimodal train shape:\", X_train_mm_pca.shape)\n",
    "print(\"Final multimodal test shape :\", X_test_mm_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "486130c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '20141009T000000'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      5\u001b[39m X_tr, X_val, y_tr, y_val = train_test_split(\n\u001b[32m      6\u001b[39m     X_train_mm_pca, y_train_tab, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m rf = RandomForestRegressor(\n\u001b[32m     10\u001b[39m     n_estimators=\u001b[32m300\u001b[39m,\n\u001b[32m     11\u001b[39m     random_state=\u001b[32m42\u001b[39m,\n\u001b[32m     12\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mrf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m pred = rf.predict(X_val)\n\u001b[32m     18\u001b[39m rmse = mean_squared_error(y_val, pred) ** \u001b[32m0.5\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\sklearn\\base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:359\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[32m    369\u001b[39m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[32m    372\u001b[39m estimator = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimator)(criterion=\u001b[38;5;28mself\u001b[39m.criterion)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2917\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2918\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2920\u001b[39m     out = X, y\n\u001b[32m   2922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1314\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1309\u001b[39m         estimator_name = _check_estimator_name(estimator)\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1312\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1331\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1333\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1022\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1020\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1021\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1025\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1026\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\asus\\Music\\real_estate_multimodal\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:878\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    876\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    881\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    882\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '20141009T000000'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_mm_pca, y_train_tab, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_tr, y_tr)\n",
    "pred = rf.predict(X_val)\n",
    "\n",
    "rmse = mean_squared_error(y_val, pred) ** 0.5\n",
    "r2 = r2_score(y_val, pred)\n",
    "\n",
    "print(\"ðŸ”¥ PCA Multimodal RF RMSE:\", rmse)\n",
    "print(\"ðŸ”¥ PCA Multimodal RF R2 :\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a76fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3040, 84)\n",
      "3040\n",
      "<class 'numpy.ndarray'> <class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_train_tab))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(X_train_mm_pca), \u001b[38;5;28mtype\u001b[39m(y_train_tab))\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_mm_pca\u001b[49m\u001b[43m)\u001b[49m.sum())\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(y_train_tab.isna().sum() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y_train_tab, \u001b[33m\"\u001b[39m\u001b[33misna\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m np.isnan(y_train_tab).sum())\n",
      "\u001b[31mTypeError\u001b[39m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "print(X_train_mm_pca.shape)\n",
    "print(len(y_train_tab))\n",
    "print(type(X_train_mm_pca), type(y_train_tab))\n",
    "print(np.isnan(X_train_mm_pca).sum())\n",
    "print(y_train_tab.isna().sum() if hasattr(y_train_tab, \"isna\") else np.isnan(y_train_tab).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c21eddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tab train numeric: (3040, 18)\n",
      "Tab test numeric : (1001, 18)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# y (target)\n",
    "y_train_tab = train_small[\"price\"].astype(float).values\n",
    "\n",
    "# Tabular features: drop target, then keep only numeric columns\n",
    "X_tab_train = train_small.drop(columns=[\"price\"], errors=\"ignore\")\n",
    "X_tab_test  = test_small.copy()\n",
    "\n",
    "X_tab_train_num = X_tab_train.select_dtypes(include=[\"number\"]).fillna(0)\n",
    "X_tab_test_num  = X_tab_test.select_dtypes(include=[\"number\"]).fillna(0)\n",
    "\n",
    "print(\"Tab train numeric:\", X_tab_train_num.shape)\n",
    "print(\"Tab test numeric :\", X_tab_test_num.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f17da40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X train: (3040, 82)\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train_mm_pca = np.hstack([X_tab_train_num.values, train_img_pca])\n",
    "X_test_mm_pca  = np.hstack([X_tab_test_num.values,  test_img_pca])\n",
    "\n",
    "print(\"Final X train:\", X_train_mm_pca.shape)\n",
    "print(\"dtype:\", X_train_mm_pca.dtype)   # should NOT be object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a303d277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ PCA Multimodal RF RMSE: 199669.9256974981\n",
      "ðŸ”¥ PCA Multimodal RF R2  : 0.7658859241493154\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_mm_pca, y_train_tab, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_tr, y_tr)\n",
    "\n",
    "pred = rf.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, pred) ** 0.5\n",
    "r2   = r2_score(y_val, pred)\n",
    "\n",
    "print(\"ðŸ”¥ PCA Multimodal RF RMSE:\", rmse)\n",
    "print(\"ðŸ”¥ PCA Multimodal RF R2  :\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21e8bfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred done âœ… (1001,) min/max: 172997.115 2204384.7666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "final_rf = RandomForestRegressor(\n",
    "    n_estimators=600,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "final_rf.fit(X_train_mm_pca, y_train_tab)\n",
    "\n",
    "test_pred = final_rf.predict(X_test_mm_pca)\n",
    "\n",
    "print(\"Pred done âœ…\", test_pred.shape, \"min/max:\", test_pred.min(), test_pred.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd59cf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred done âœ… (1001,) min/max: 172997.115 2204384.7666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "final_rf = RandomForestRegressor(\n",
    "    n_estimators=600,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "final_rf.fit(X_train_mm_pca, y_train_tab)\n",
    "\n",
    "test_pred = final_rf.predict(X_test_mm_pca)\n",
    "\n",
    "print(\"Pred done âœ…\", test_pred.shape, \"min/max:\", test_pred.min(), test_pred.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b65e4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2591820310</td>\n",
       "      <td>3.758784e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7974200820</td>\n",
       "      <td>8.104149e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7701450110</td>\n",
       "      <td>1.140396e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9522300010</td>\n",
       "      <td>1.697151e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9510861140</td>\n",
       "      <td>7.161204e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         price\n",
       "0  2591820310  3.758784e+05\n",
       "1  7974200820  8.104149e+05\n",
       "2  7701450110  1.140396e+06\n",
       "3  9522300010  1.697151e+06\n",
       "4  9510861140  7.161204e+05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test_small[\"id\"].astype(str).values,\n",
    "    \"price\": test_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_rf_pca.csv\", index=False)\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2611fb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model âœ…\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(final_rf, \"final_rf_pca.joblib\")\n",
    "print(\"Saved model âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dca100a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved âœ… submission_rf_pca.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2591820310</td>\n",
       "      <td>3.758784e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7974200820</td>\n",
       "      <td>8.104149e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7701450110</td>\n",
       "      <td>1.140396e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9522300010</td>\n",
       "      <td>1.697151e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9510861140</td>\n",
       "      <td>7.161204e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         price\n",
       "0  2591820310  3.758784e+05\n",
       "1  7974200820  8.104149e+05\n",
       "2  7701450110  1.140396e+06\n",
       "3  9522300010  1.697151e+06\n",
       "4  9510861140  7.161204e+05"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test_small[\"id\"].astype(str).values,\n",
    "    \"price\": test_pred\n",
    "})\n",
    "submission.to_csv(\"submission_rf_pca.csv\", index=False)\n",
    "print(\"Saved âœ… submission_rf_pca.csv\")\n",
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8e603c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV exists: True\n",
      "Model exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"CSV exists:\", os.path.exists(\"submission_rf_pca.csv\"))\n",
    "print(\"Model exists:\", os.path.exists(\"final_rf_pca.joblib\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ed4b476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2591820310</td>\n",
       "      <td>3.758784e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7974200820</td>\n",
       "      <td>8.104149e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7701450110</td>\n",
       "      <td>1.140396e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9522300010</td>\n",
       "      <td>1.697151e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9510861140</td>\n",
       "      <td>7.161204e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         price\n",
       "0  2591820310  3.758784e+05\n",
       "1  7974200820  8.104149e+05\n",
       "2  7701450110  1.140396e+06\n",
       "3  9522300010  1.697151e+06\n",
       "4  9510861140  7.161204e+05"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"submission_rf_pca.csv\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ed2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
